{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd6ee0a0-39ab-4ffb-a347-98f4d76a8ec8",
   "metadata": {},
   "source": [
    "#### Uncomment to install biobox - used in PDB parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aec8c668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install biobox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe6fb0c-e649-42c3-8899-e75b207811c3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Imports + functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "03241443",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import biobox as bb\n",
    "from tqdm import tqdm\n",
    "\n",
    "def setup_working_directory():\n",
    "    \n",
    "    current = os.getcwd()\n",
    "    working = 'Fitting'\n",
    "    working_path = os.path.join(current, working)\n",
    "    try:\n",
    "        os.mkdir(working_path)\n",
    "        print('Making directory ', working_path)\n",
    "    except OSError as error:\n",
    "        print(str(error)[11:])\n",
    "        \n",
    "    try:\n",
    "        os.mkdir(working_path+'/fitdata')\n",
    "        print('Making directory for fit data')\n",
    "    except OSError as error:\n",
    "        print(str(error)[11:])\n",
    "    print('Complete')\n",
    "    return working_path\n",
    "\n",
    "\n",
    "def pdb_2_biobox(pdb_file):\n",
    "    M = bb.Molecule()\n",
    "    M.import_pdb(pdb_file)\n",
    "    return M\n",
    "\n",
    "\n",
    "def extract_CA_coordinates(M):\n",
    "    ca_idx = (M.data['name']=='CA').values\n",
    "    ca_coords = M.coordinates[0][ca_idx]\n",
    "    \n",
    "    if ca_coords.shape[0] != M.data['resid'].nunique():\n",
    "        raise Exception(\"You better check your PDB... The number of CA atoms does not equal the number of ResIDs in your PDB file!\") \n",
    "    else:\n",
    "        return ca_coords\n",
    "\n",
    "    \n",
    "def extract_sequence(M):\n",
    "    \n",
    "    \n",
    "    aa_names = {\n",
    "                'A': 'ALA', 'C': 'CYS', 'D': 'ASP', 'E': 'GLU',\n",
    "                'F': 'PHE', 'G': 'GLY', 'H': 'HIS', 'I': 'ILE',\n",
    "                'K': 'LYS', 'L': 'LEU', 'M': 'MET', 'N': 'ASN',\n",
    "                'P': 'PRO', 'Q': 'GLN', 'R': 'ARG', 'S': 'SER',\n",
    "                'T': 'THR', 'V': 'VAL', 'W': 'TRP', 'Y': 'TYR'\n",
    "                }\n",
    "\n",
    "    names_aa = {y: x for x, y in aa_names.items()}\n",
    "    \n",
    "    ca_idx = (M.data['name']=='CA').values\n",
    "    resnames = M.data['resname'][ca_idx].map(names_aa).values\n",
    "    \n",
    "    if resnames.shape[0] != M.data['resid'].nunique():\n",
    "        raise Exception(\"You better check your PDB... The number of CA atoms does not equal the number of ResIDs in your PDB file!\") \n",
    "    else:\n",
    "        return resnames\n",
    "\n",
    "\n",
    "def write_fingerprint_file(number_chains, sequence, secondary_structure, working_path):\n",
    "    \n",
    "    assert isinstance(number_chains, int), 'Yikes... The number of chains is not int type!'\n",
    "    \n",
    "    if number_chains > 1:\n",
    "        print('Are sure you have more than one chain - if not this will cause segmentation errors later! You have been warned...')\n",
    "    \n",
    "    seq_run = ''.join(list(sequence))\n",
    "    ss_run = ''.join(list(secondary_structure))\n",
    "    \n",
    "    if len(seq_run) != len(ss_run):\n",
    "        raise Exception(\"Uh Oh... The length of sequence and secondary structure is not equal!\") \n",
    "    \n",
    "    f = open(working_path+\"/fingerPrint1.dat\", \"w\")\n",
    "    f.write(str(number_chains))\n",
    "    f.write('\\n \\n')\n",
    "    f.write(seq_run)\n",
    "    f.write('\\n \\n')\n",
    "    f.write(ss_run)\n",
    "    f.close()\n",
    "    \n",
    "    \n",
    "def write_coordinates_file(ca_coords, working_path):\n",
    "    \n",
    "    assert type(coords).__module__ == np.__name__, 'Thats never good... the CA coordinates are not a numpy array'\n",
    "    np.savetxt(working_path+'/coordinates1.dat', coords, delimiter=' ', fmt='%s',newline='\\n', header='', footer='')\n",
    "    \n",
    "    \n",
    "def write_mixture_file(working_path):\n",
    "    # if default:\n",
    "    f = open(working_path+\"/mixtureFile.dat\", \"w\")\n",
    "    f.write(str(1))\n",
    "        \n",
    "#     else:\n",
    "#          copy input file\n",
    "\n",
    "\n",
    "def write_varysections_file(varying_sections, working_path):\n",
    "    # auto: run beta sheet breaking code; write output sections to file\n",
    "    f = open(working_path+\"/varyingSectionSecondary1.dat\", \"w\")\n",
    "    for i, s in enumerate(varying_sections):\n",
    "        f.write(str(s))\n",
    "        \n",
    "        if i < len(varying_sections)-1:\n",
    "            f.write('\\n')\n",
    "    f.close()\n",
    "\n",
    "    \n",
    "def copy_saxs(SAXS_file, working_path):\n",
    "    \n",
    "    saxs_arr = np.genfromtxt(SAXS_file)\n",
    "    \n",
    "    if saxs_arr.shape[1] == 3:\n",
    "        saxs_arr = saxs_arr[:,:2]\n",
    "        \n",
    "    np.savetxt(working_path+'/Saxs.dat', saxs_arr, delimiter=' ', fmt='%s',newline='\\n', header='', footer='')\n",
    "\n",
    "\n",
    "def read_dssp_file(dssp_filename):\n",
    "    \n",
    "    simplify_dict = {'H': 'H', 'B': 'S', 'E': 'S', 'G': 'H', 'I': 'H', 'T': '-', 'S': '-', '-': '-', ' ': '-'}\n",
    "    \n",
    "    lines=[]\n",
    "    with open(dssp_filename) as input_data:\n",
    "        # Skips text before the beginning of the interesting block:\n",
    "        for line in input_data:\n",
    "            if line.strip() == '#  RESIDUE AA STRUCTURE BP1 BP2  ACC     N-H-->O    O-->H-N    N-H-->O    O-->H-N    TCO  KAPPA ALPHA  PHI   PSI    X-CA   Y-CA   Z-CA': \n",
    "                break\n",
    "        # Reads text until the end of the block:\n",
    "        for line in input_data:  # This keeps reading the file\n",
    "            lines.append(simplify_dict[line[16]])\n",
    "    return ''.join(lines)\n",
    "    \n",
    "    \n",
    "def simplify_secondary(dssp_struct):\n",
    "    \n",
    "    simplify_dict = {'H': 'H', 'B': 'S', 'E': 'S', 'G': 'H', 'I': 'H', 'T': '-', 'S': '-', '-': '-', ' ': '-'}\n",
    "    \n",
    "    secondary_structure = []\n",
    "    \n",
    "    for s in dssp_struct:\n",
    "        \n",
    "        if s not in list(simplify_dict.keys()):\n",
    "            print('>>> ', s, ' <<<')\n",
    "            raise Exception('Secondary structure not recognised!')\n",
    "            \n",
    "        secondary_structure.append(simplify_dict[s])\n",
    "        \n",
    "    return secondary_structure\n",
    "\n",
    "\n",
    "def write_sh_file(working_path, fit_n_times, min_q, max_q, max_fit_steps):\n",
    "    \n",
    "    curr = os.getcwd()\n",
    "    run_file = curr + '/RunMe.sh'\n",
    "\n",
    "    with open(run_file, 'w+') as fout:\n",
    "        fout.write('#!/bin/bash')\n",
    "        \n",
    "        saxs_file = working_path+'/Saxs.dat'\n",
    "        FP_file = working_path+\"/fingerPrint1.dat\"\n",
    "        coords_file = working_path+'/coordinates1.dat'\n",
    "        varying_file = working_path+\"/varyingSectionSecondary1.dat\"\n",
    "        mixture_file = working_path+\"/mixtureFile.dat\"\n",
    "        \n",
    "        # Auto assign min / max q from SAXS profile\n",
    "        # saxs_arr = np.genfromtxt(saxs_file)\n",
    "        # min_q = np.round(saxs_arr[:,0].min(),2)\n",
    "        # max_q = np.round(saxs_arr[:,0].max(),2)\n",
    "        \n",
    "        fout.write('\\nfor i in {1..'+str(fit_n_times)+'}')\n",
    "\n",
    "        fout.write('\\n\\ndo')\n",
    "        fout.write('\\n\\n   echo \" Run number : $i \"')\n",
    "        fout.write('\\n\\n   ./predictStructure ' + saxs_file + ' ' + working_path+'/' + ' ' + coords_file + ' ' + 'none' + ' ' + varying_file + ' ' + '1' + ' ' + 'none' + \\\n",
    "                   ' ' + 'none' + ' ' + str(min_q) + ' ' + str(max_q) + ' ' + str(max_fit_steps) + ' ' + working_path+'/fitdata/fitmolecule$i' + ' ' + working_path+'/fitdata/scatter$i.dat' + ' ' + mixture_file + ' ' +'1')\n",
    "                   \n",
    "        fout.write('\\n\\ndone')\n",
    "        \n",
    "    print('Successfully written bash script to: ', working_path+run_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0794407-32c2-4cd4-97f4-50affb4c68e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# SMARCAL Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39b3ba6-1d4e-42e1-b6be-a3a77bab6f93",
   "metadata": {},
   "source": [
    "#### Create a working directory for Carbonara - input files & predictions will be written to this directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "62674796-412c-43d8-b4d7-4969537a4f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making directory  /Users/josh/Documents/PhD/TEMP_Carb/CarbonARA/Fitting\n",
      "Making directory for fit data\n"
     ]
    }
   ],
   "source": [
    "working_path = setup_working_directory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ad8b5f-9753-4615-a930-d89681009018",
   "metadata": {},
   "source": [
    "#### Provide a PDB containing the known structure for protein - xyz coordinates and sequence extracted from PDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "e4414bfb-6796-46ef-86c2-cccd87028131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a PDB file location\n",
    "pdb_file = 'Example/SMARCAL/human_SMARCAL1.pdb'\n",
    "\n",
    "# Read in a pdb file\n",
    "M = pdb_2_biobox(pdb_file)\n",
    "\n",
    "# Extract coordinates + primary sequence\n",
    "coords = extract_CA_coordinates(M)\n",
    "sequence = extract_sequence(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606c6a00-e90c-4812-89bd-78f60f97775c",
   "metadata": {},
   "source": [
    "#### Carbonara requires the protein's secondary structure - user can copy and paste a string or give a DSSP file!\n",
    "\n",
    "> Note: Carbonara uses a simplified secondary structure dictionary: H (alpha helices), S (beta strands), and - (Linkers/Loops) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "7de31d55-0e52-4406-84d0-9791639a203b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually defining the simplified secondary structure string\n",
    "secondary = ['------SSSSSSS----SSSSSS---HHHHHHHH-----SSS----SSSSSHHHHHHHHHHH-----SSSS---HHHHHH---HHH-------------------HHHHH---HHHHHHHHHHHH---SSSS-------HHHHHHHHHHHHHH---SSSSS----HHHHHHHHHHH-----HHHSSS------------SSSSSHHHH------------SSS---HHHH-----HHHHHHHHHHH---SSSSS--------HHHHHHHHHHH-------HHHHHHHH---SS---SSS------HHHHHHHHHHHH-----HHHH------SSSSSS---HH---HHHHHHHHHHHHHHH-----HHHHHHHHHHHHHHHHHHHHHHHHHHHHHHHH-----SSSS---HHHHHHHHHHHHH----SSSS-------HHHHHHHHHHH-----SSSSS--------------SSSS------HHHHHHHH-----------SSSSSSS-----HHHHHHHHHHHHHHHHH---------HHHH--']\n",
    "\n",
    "# --- Simplify your secondary structure string ---\n",
    "\n",
    "# Have DSSP secondary structure string? Simplify with:\n",
    "# secondary = simplify_secondary(DSSP_string)\n",
    "\n",
    "# --- DSSP file procedure ---\n",
    "\n",
    "# Just have a DSSP file?\n",
    "# secondary = read_dssp_file(DSSP_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a8943a-790f-442a-ab56-c5fb73d13739",
   "metadata": {},
   "source": [
    "#### Writing files to be used as input for Carbonara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "c05512b8-ad6a-4f31-9394-c31a49e157af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write files ready for Carbonara!\n",
    "write_fingerprint_file(1, sequence, secondary, working_path)\n",
    "write_coordinates_file(coords, working_path)\n",
    "write_mixture_file(working_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e065974a-9799-4992-a51b-76b5659e66a2",
   "metadata": {},
   "source": [
    "#### Sections to be resampled - User can manually select these or have these automatically assigned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "51dcfe46-eea9-4a57-9366-4610aaf60172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually defining sections to change\n",
    "varying_sections = [43, 51, 79, 81]  # <<< Give us your selection! #\n",
    "write_varysections_file(varying_sections, working_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384a7eae-e11b-4339-a436-d29ac1cc5a68",
   "metadata": {},
   "source": [
    "#### Provide a SAXS profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "a8875887-161f-47f0-8009-2a0d92133cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy SAXS data file into correct format\n",
    "SAXS_file = 'Example/SMARCAL/smrclcnc_a2.dat'\n",
    "copy_saxs(SAXS_file, working_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bf4daf-6910-4314-b458-41e2be61e6a8",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Generate bash file to run Carbonara\n",
    "\n",
    "**Inputs**\n",
    " > fit_n_times   : number of unique fits to be generated (sequentially)\n",
    " \n",
    " > min_q         : lower bound q in SAXS data\n",
    " \n",
    " > max_q         : upper bound q in SAXS data\n",
    " \n",
    " > max_fit_steps : maximum number of fitting iterations to be performed (recommend 4000-10,000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "956339f0-6dcd-4097-a69e-3c35e559faac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully written bash script to:  /Users/josh/Documents/PhD/TEMP_Carb/CarbonARA/Fitting/Users/josh/Documents/PhD/TEMP_Carb/CarbonARA/RunMe.sh\n"
     ]
    }
   ],
   "source": [
    "write_sh_file(working_path=working_path, fit_n_times=3, min_q=0.02, max_q=0.25, max_fit_steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "11b0bb01-2498-41e8-9f8d-76aa5166e763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Run number : 1 \n",
      " Run number : 2 \n",
      " Run number : 3 \n"
     ]
    }
   ],
   "source": [
    "!sh RunMe.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075141ee-788d-463c-961c-accf3c17ce1f",
   "metadata": {},
   "source": [
    "**********"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
